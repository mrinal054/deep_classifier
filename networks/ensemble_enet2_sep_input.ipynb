{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9088a182-6bde-4206-a37c-51f88f8d6aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/research/m324371/PyEnv/adnexal/lib64/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/research/m324371/PyEnv/adnexal/lib64/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B2_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This architecture uses EfficientNetB2. It has three EfficientNetB2 models. \n",
    "\n",
    "The first EfficientNetB2 takes the image, the EfficientNetB2 ResNet18 takes the fluid component, \n",
    "and the third EfficientNetB2 takes the solid component. \n",
    "\n",
    "Then, their feature maps are concatenated. A classification head is then added.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "class EnsembleEnet2(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_classes,\n",
    "                 out_channels:list=None, # for instance [1024, 512, 256]. Used in classification head\n",
    "                 dropout:float=0.3,\n",
    "                ):\n",
    "        super(EnsembleEnet2, self).__init__()\n",
    "        \n",
    "        # Load pretrained EfficientNetB2\n",
    "        self.model1 = models.efficientnet_b2(pretrained=True)\n",
    "        self.model2 = models.efficientnet_b2(pretrained=True)\n",
    "        self.model3 = models.efficientnet_b2(pretrained=True)\n",
    "        \n",
    "        # Remove the fully connected layers to extract 2D feature maps\n",
    "        self.model1 = nn.Sequential(*list(self.model1.children())[:-2])  # Feature map (1408 x H x W)\n",
    "        self.model2 = nn.Sequential(*list(self.model2.children())[:-2])  # Feature map (1408 x H x W)\n",
    "        self.model3 = nn.Sequential(*list(self.model3.children())[:-2])  # Feature map (1408 x H x W)\n",
    "\n",
    "        # Conv-ReLU-BN block after concatenating feature maps\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(1408 * 3, out_channels[0], kernel_size=3, padding=1),  # Convolution with 1024 output channels\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_channels[0])\n",
    "        )\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # Output size: (out_channels x 1 x 1)\n",
    "        \n",
    "        # Classification head\n",
    "        layers = []\n",
    "        \n",
    "        # Create fully connected layers based on channel_list\n",
    "        for i in range(len(out_channels) - 1):\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            layers.append(nn.Linear(out_channels[i], out_channels[i + 1]))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Final layer for classification\n",
    "        layers.append(nn.Linear(out_channels[-1], num_classes))\n",
    "\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract 2D feature maps from both models\n",
    "        image = x[:,0:1,:,:]\n",
    "        fluid = x[:,1:2,:,:]\n",
    "        solid = x[:,2:3,:,:]\n",
    "        \n",
    "        model1_features = self.model1(x)  # Output: (1408 x H_resnet x W_resnet)\n",
    "        model2_features = self.model2(x)  # Output: (1408 x H_resnet x W_resnet)\n",
    "        model3_features = self.model3(x)  # Output: (1408 x H_resnet x W_resnet)\n",
    "        \n",
    "        # Concatenate the feature maps along the channel dimension\n",
    "        combined_features = torch.cat((model1_features, model2_features, model3_features), dim=1)  # (1408*3 x H x W)\n",
    "        \n",
    "        # Apply the convolutional block\n",
    "        conv_out = self.conv_block(combined_features)  # Output: (out_channels x H x W)\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        pooled_out = self.avg_pool(conv_out)  # Output: (out_channels x 1 x 1)\n",
    "        \n",
    "        # Flatten the pooled output\n",
    "        flattened = pooled_out.view(pooled_out.size(0), -1)  # Output: (out_channels,)\n",
    "        \n",
    "        # Classification using fully connected layers\n",
    "        output = self.fc(flattened)  # Output: (num_classes)\n",
    "        \n",
    "        return output\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    num_classes = 10  # Set the number of output classes \n",
    "    out_channels = [1024]\n",
    "    dropout = 0.3\n",
    "    model = EnsembleEnet2(num_classes=num_classes, out_channels=out_channels, dropout=dropout)\n",
    "    \n",
    "    # Test with random input (batch_size=4, num_channels=3, height=224, width=224)\n",
    "    x = torch.randn(4, 3, 224, 224)\n",
    "    output = model(x)\n",
    "    print(output.shape)  # Should output: torch.Size([4, num_classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb50797-a98d-4bab-b3a7-a3eda8001101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
